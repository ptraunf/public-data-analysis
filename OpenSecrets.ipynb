{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from datetime import datetime\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ],
   "id": "1cf790ed79a05226"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "d8ec71a769efc270"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Function Defs\n",
    "def custom_title_case(s):\n",
    "    return s.upper()\n",
    "\n",
    "def convert_date(d):\n",
    "    dateTimeObj = datetime.strptime(str(d), \"%m-%d-%Y\")\n",
    "    return dateTimeObj.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "def fix_recipient_name(recipient):\n",
    "    recipient = re.sub(r'\\(.*\\)$', '', recipient).strip()\n",
    "    parts = recipient.split(', ')\n",
    "    if len(parts) > 1:\n",
    "        first_part = custom_title_case(parts[0])\n",
    "        rest = ' '.join(parts[1:])\n",
    "        recipient_fixed = f\"{custom_title_case(rest)} {first_part}\"\n",
    "    else:\n",
    "        recipient_fixed = custom_title_case(recipient)\n",
    "    return recipient_fixed\n",
    "\n",
    "def split_contributor(contributor):\n",
    "    p = contributor.split('  ')\n",
    "    zip_code_match = re.search(r'(\\b\\d{5}\\b)$', p[1])\n",
    "    zip_code = zip_code_match.group(1) if zip_code_match else None\n",
    "\n",
    "    village_match = re.search(r'(^[a-zA-Z ]+),', p[1])\n",
    "    village = village_match.group(1) if village_match else None\n",
    "\n",
    "    name_parts = p[0].split(', ')\n",
    "    first_name = custom_title_case(' '.join(name_parts[1:])) if len(name_parts) > 1 else ''\n",
    "    last_name = custom_title_case(name_parts[0])\n",
    "\n",
    "    return last_name, first_name, village, zip_code\n",
    "\n",
    "def clean_amount(amount):\n",
    "    cleaned_amount = re.sub(r'[^\\d]', '', amount)\n",
    "    return int(cleaned_amount) if cleaned_amount else 0\n",
    "\n",
    "def is_ny_zip_code(zip_code):\n",
    "    return 10001 <= int(zip_code) <= 14975 if zip_code and zip_code.isdigit() else False\n",
    "\n",
    "def process_data(url):\n",
    "    disclaimer = 'FEDERAL LAW PROHIBITS THE USE OF CONTRIBUTOR INFORMATION FOR THE PURPOSE OF SOLICITING CONTRIBUTIONS OR FOR ANY COMMERCIAL PURPOSE.'\n",
    "    all_data = []\n",
    "    page = 1\n",
    "\n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument(\"--headless\")\n",
    "    chrome_options.add_argument(\"--no-sandbox\")\n",
    "    chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
    "    chrome_options.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\")\n",
    "\n",
    "    service = Service('/usr/local/bin/chromedriver-linux64/chromedriver')\n",
    "\n",
    "    driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "\n",
    "    while True:\n",
    "        full_url = f\"{url}&page={page}\"\n",
    "        driver.get(full_url)\n",
    "\n",
    "        try:\n",
    "            table = WebDriverWait(driver, 20).until(\n",
    "                EC.presence_of_element_located((By.XPATH, '//table'))\n",
    "            )\n",
    "\n",
    "            table_html = table.get_attribute('outerHTML')\n",
    "\n",
    "            df = pd.read_html(table_html)[0]\n",
    "\n",
    "            if df.empty:\n",
    "                break\n",
    "            else:\n",
    "                all_data.append(df)\n",
    "                page += 1\n",
    "\n",
    "        except Exception as e:\n",
    "            break\n",
    "\n",
    "    driver.quit()\n",
    "\n",
    "    if all_data:\n",
    "        df = pd.concat(all_data, ignore_index=True)\n",
    "        df.drop(df.tail(1).index, inplace=True)\n",
    "        df.columns = ['Category', 'Contributor', 'Employer', 'Occupation', 'Date', 'Amount', 'Recipient', 'Recipient Jurisdiction']\n",
    "        df['Party'] = df['Recipient'].str.extract(r'\\(([A-Z]+)\\)$')\n",
    "        df['Recipient'] = df['Recipient'].apply(fix_recipient_name)\n",
    "        df['Amount'] = df['Amount'].apply(clean_amount)\n",
    "        df = df[~df['Category'].str.contains(disclaimer)]\n",
    "        split_contributions = df['Contributor'].apply(lambda x: pd.Series(split_contributor(x), index=['Last Name', 'First Name', 'Village', 'Zip Code']))\n",
    "        df = pd.concat([df, split_contributions], axis=1)\n",
    "        df = df[df['Zip Code'].apply(is_ny_zip_code)]\n",
    "        df['Date'] = df['Date'].apply(convert_date)\n",
    "\n",
    "        columns_order = ['Category', 'Contributor', 'Last Name', 'First Name', 'Village', 'Zip Code', 'Employer', 'Occupation', 'Date', 'Amount', 'Recipient', 'Party', 'Recipient Jurisdiction']\n",
    "        df = df[columns_order]\n",
    "    else:\n",
    "        df = pd.DataFrame()\n",
    "\n",
    "    return df\n",
    "\n",
    "def generate_urls_and_aggregate_data(donor_data):\n",
    "    base_url = \"https://www.opensecrets.org/donor-lookup/results?name=\"\n",
    "    aggregated_data = pd.DataFrame()\n",
    "    for index, row in donor_data.iterrows():\n",
    "        full_name = f\"{row['FNAME']}+{row['LNAME']}\"\n",
    "        url = f\"{base_url}{full_name}\"\n",
    "        data = process_data(url)\n",
    "        if not data.empty:\n",
    "            aggregated_data = pd.concat([aggregated_data, data], ignore_index=True)\n",
    "    return aggregated_data"
   ],
   "id": "8f0a9f17a6c6e56f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Tests\n",
    "\n",
    "def test_convert_date():\n",
    "    pass\n",
    "\n",
    "def test_split_contributor():\n",
    "    pass"
   ],
   "id": "f4010743241899f6"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
